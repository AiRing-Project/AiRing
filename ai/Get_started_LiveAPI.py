# -*- coding: utf-8 -*-
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
## Run

To run the script:

```
python Get_started_LiveAPI.py
```
"""

import asyncio
import os
import sys
import traceback
import time

import pyaudio
import json
from google import genai
from google.genai import types

from dotenv import load_dotenv

import websockets

load_dotenv(".env")

try:
    api_key = os.environ["GOOGLE_API_KEY"]
except KeyError as exc:
    raise RuntimeError(
        "Environment variable GOOGLE_API_KEY is not set. "
        "Create a .env file or export the variable before running."
    ) from exc

client = genai.Client(api_key=api_key)

if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup

    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup
    ExceptionGroup = exceptiongroup.ExceptionGroup

pya = pyaudio.PyAudio()

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 2048

MODEL = "models/gemini-2.0-flash-live-001"

DEFAULT_MODE = "none"

# ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ì •ì˜
AI_VOICES = {
    "1": "Aoede",
    "2": "Puck",
    "3": "Charon",
    "4": "Kore",
    "5": "Fenrir",
    "6": "Leda",
    "7": "Orus",
    "8": "Zephyr"
}

END_KEYWORDS = ["í†µí™” ì¢…ë£Œ", "ì¢…ë£Œí• ê²Œ", "ëë‚¼ê²Œ", "ê·¸ë§Œí•˜ê³  ì‹¶ì–´", 
                    "ê·¸ë§Œí• ë˜","ê·¸ë§Œí• ê²Œ", "ëŠì„ê²Œ", "ëŠì–´", "ëŠëŠ”ë‹¤"]

def select_voice():
    print("\n=== AI ìŒì„± ì„ íƒ ===")
    print("ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡:")
    for key, voice in AI_VOICES.items():
        print(f"{key}. {voice}")
    
    while True:
        choice = input("\nì›í•˜ëŠ” ìŒì„± ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-8): ")
        if choice in AI_VOICES:
            return AI_VOICES[choice]
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-8 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE):
        self.video_mode = video_mode
        self.selected_voice = select_voice()  # ìŒì„± ì„ íƒ ì¶”ê°€
        
        self.audio_in_queue = None
        self.out_queue = None

        self.session = None
        self._tasks = []  # íƒœìŠ¤í¬ ê´€ë¦¬ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€

        self.receive_audio_task = None
        self.play_audio_task = None

        self.conversation_log = []
        self.ai_buffer = "" #AI ì‘ë‹µ ëˆ„ì  ë²„í¼ ì¶”ê°€
        self.user_buffer = "" #ì‚¬ìš©ì ì‘ë‹µ ëˆ„ì  ë²„í¼ ì¶”ê°€

        self.last_user_input_time = time.time()
        self.session_active = True

    async def send_realtime(self):
        try:
            while self.session_active:
                try:
                    msg = await self.out_queue.get()
                    blob = types.Blob(data=msg["data"], mime_type="audio/pcm;rate=16000")
                    await self.session.send_realtime_input(audio=blob)
                except websockets.exceptions.ConnectionClosedOK:
                    # ì •ìƒì ì¸ ì—°ê²° ì¢…ë£Œ
                    return
                except Exception as e:
                    if not self.session_active:
                        return
                    print(f"send_realtime ì˜¤ë¥˜: {str(e)}")
                    continue
        except asyncio.CancelledError:
            return
        except Exception as e:
            print(f"send_realtime ì˜ˆì™¸: {str(e)}")
            return

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        if __debug__:
            kwargs = {"exception_on_overflow": False}
        else:
            kwargs = {}
        while self.session_active:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        try:
            while self.session_active:
                turn = self.session.receive()
                async for response in turn:
                    if not self.session_active:
                        return

                    # ì‚¬ìš©ì ìŒì„± í…ìŠ¤íŠ¸ ëˆ„ì  (ë¶€ë¶„ ì‘ë‹µ)
                    if (
                    hasattr(response, "server_content")
                    and hasattr(response.server_content, "input_transcription")
                    and response.server_content.input_transcription
                    and hasattr(response.server_content.input_transcription, "text")
                    and response.server_content.input_transcription.text):
                        user_text = response.server_content.input_transcription.text
                        self.user_buffer += user_text
                        self.last_user_input_time = time.time()  # ë§ˆì§€ë§‰ ì…ë ¥ ì‹œê° ê°±ì‹ 

                        # ì¢…ë£Œ ë°œí™” ê°ì§€
                        if any(keyword in user_text for keyword in END_KEYWORDS):
                            print("ì‚¬ìš©ì ì¢…ë£Œ ë°œí™” ê°ì§€, ì„¸ì…˜ ì¢…ë£Œ")
                            self.session_active = False
                            if self.session:
                                await self.session.close()
                            return

                    # AI ì‘ë‹µ í…ìŠ¤íŠ¸ ëˆ„ì  (ë¶€ë¶„ ì‘ë‹µ)
                    if (
                    hasattr(response, "server_content")
                    and hasattr(response.server_content, "output_transcription")
                    and response.server_content.output_transcription
                    and hasattr(response.server_content.output_transcription, "text")
                    and response.server_content.output_transcription.text):
                        
                        ai_text = response.server_content.output_transcription.text
                        self.ai_buffer += ai_text

                    # í„´ ì¢…ë£Œ ì‹ í˜¸(turn_complete)ì—ì„œ í•œ ë²ˆì— ì €ì¥
                    if (
                    hasattr(response, "server_content")
                    and hasattr(response.server_content, "turn_complete")
                    and response.server_content.turn_complete):
                        
                        if self.user_buffer.strip():
                            self.conversation_log.append({"role": "USER", "text": self.user_buffer.strip()})
                            self.user_buffer = ""
                        if self.ai_buffer.strip():
                            self.conversation_log.append({"role": "AI", "text": self.ai_buffer.strip()})
                            self.ai_buffer = ""

                    if data := response.data:
                        if self.session_active:  # ì„¸ì…˜ì´ í™œì„±í™”ëœ ìƒíƒœì—ì„œë§Œ íì— ì¶”ê°€
                            self.audio_in_queue.put_nowait(data)
                        continue
                    if text := response.text:
                        print(text, end="")

                # í ì •ë¦¬
                if not self.session_active:
                    while not self.audio_in_queue.empty():
                        try:
                            self.audio_in_queue.get_nowait()
                        except asyncio.QueueEmpty:
                            break
                    return

        except asyncio.CancelledError:
            return
        except Exception as e:
            print(f"receive_audio ì˜¤ë¥˜: {str(e)}")
            return

    async def timeout_checker(self):
        while self.session_active:
            await asyncio.sleep(1)
            if time.time() - self.last_user_input_time > 30:
                print("30ì´ˆ ë¬´ì‘ë‹µ, ì„¸ì…˜ ì¢…ë£Œ")
                self.session_active = False
                if self.session:
                    await self.session.close()
                # ìƒì„±í•œ íƒœìŠ¤í¬ë§Œ ì·¨ì†Œ
                for task in self._tasks:
                    task.cancel()
                await asyncio.gather(*self._tasks, return_exceptions=True)
                break

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        
        # ì˜¤ë””ì˜¤ ë²„í¼ ê´€ë¦¬ - AI ëŒ€í™” ì‹œì‘ ì‹œì  ê³ ë ¤
        buffer = []
        initial_buffer_size = 5  # ì´ˆê¸° ë²„í¼ í¬ê¸° (AI ì²« ì‘ë‹µì„ ìœ„í•œ ì¶©ë¶„í•œ ë²„í¼)
        minimum_buffer_size = 3  # ìµœì†Œ ë²„í¼ í¬ê¸° (ëŒ€í™” ì¤‘ ëŠê¹€ ë°©ì§€)
        
        print("ğŸ”Š ì˜¤ë””ì˜¤ ë²„í¼ ì¤€ë¹„ ì¤‘...")
        
        # ì´ˆê¸° ë²„í¼ ì±„ìš°ê¸° - AI ì²« ì‘ë‹µì„ ìœ„í•œ ì¤€ë¹„
        while len(buffer) < initial_buffer_size:
            try:
                if not self.audio_in_queue.empty():
                    chunk = await asyncio.wait_for(self.audio_in_queue.get(), timeout=0.1)  # ì²« ì‘ë‹µì„ ìœ„í•œ ì—¬ìœ  ì‹œê°„
                    buffer.append(chunk)
                else:
                    await asyncio.sleep(0.05)  # ëŒ€ê¸° ì‹œê°„
            except asyncio.TimeoutError:
                continue
            except asyncio.CancelledError:
                return
        
        print("ğŸ”Š ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘")
        
        try:
            while self.session_active:
                # ë²„í¼ê°€ ìµœì†Œ í¬ê¸° ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ ë” ì±„ì›€
                if len(buffer) <= minimum_buffer_size:
                    refill_count = 0
                    while len(buffer) < initial_buffer_size and refill_count < 3:  # ì•ˆì •ì ì¸ ëŒ€í™”ë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ë¦¬í•„
                        try:
                            if not self.audio_in_queue.empty():
                                chunk = await asyncio.wait_for(self.audio_in_queue.get(), timeout=0.08)  # ëŒ€í™” ì¤‘ ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„
                                buffer.append(chunk)
                                refill_count += 1
                            else:
                                break
                        except asyncio.TimeoutError:
                            break
                
                # ë²„í¼ì—ì„œ ì²­í¬ ì¬ìƒ
                if buffer:
                    chunk = buffer.pop(0)
                    await asyncio.to_thread(stream.write, chunk)
                else:
                    # ë²„í¼ê°€ ë¹„ì—ˆìœ¼ë©´ íì—ì„œ ì§ì ‘ ê°€ì ¸ì™€ ì¬ìƒ
                    try:
                        if not self.audio_in_queue.empty():
                            chunk = await asyncio.wait_for(self.audio_in_queue.get(), timeout=0.08)  # ëŒ€í™” ì¤‘ ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„
                            await asyncio.to_thread(stream.write, chunk)
                        else:
                            await asyncio.sleep(0.03)  # ëŒ€í™” ì¤‘ ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„
                    except asyncio.TimeoutError:
                        await asyncio.sleep(0.03)
        
        except asyncio.CancelledError:
            print("ğŸ”Š ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ë‹¨")

    async def run(self):
        try:
            # ìŒì„± ì„¤ì • ì—…ë°ì´íŠ¸
            CONFIG = types.LiveConnectConfig(
                response_modalities=["AUDIO"],
                speech_config=types.SpeechConfig(
                    language_code="ko-KR",  # í•œêµ­ì–´ ì„¤ì •
                    voice_config=types.VoiceConfig(
                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                            voice_name=self.selected_voice
                        )
                    )
                ),
                system_instruction=types.Part(
                    text=(
                        "ë„ˆëŠ” ì˜¤ëŠ˜ í•˜ë£¨ ì¼ê¸° ì‘ì„±ì„ ë•ëŠ” ëŒ€í™” ë„ìš°ë¯¸ì•¼."
                        "ì‚¬ìš©ìì—ê²Œ ì˜¤ëŠ˜ ì–´ë–¤ ì¼ì´ ìˆì—ˆëŠ”ì§€, ê¸°ë¶„ì€ ì–´ë• ëŠ”ì§€, ê¸°ì–µì— ë‚¨ëŠ” ì¼ì€ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ì°¨ê·¼ì°¨ê·¼ í•˜ë‚˜ì”© ì§ˆë¬¸í•´ì¤˜."
                        "ì¼ê¸° ì‘ì„±ì— ë„ì›€ì´ ë  ë§Œí•œ ì§ˆë¬¸ì„ ì´ì–´ê°€ê³ , í•œ ë²ˆì— ì§ˆë¬¸ì€ í•˜ë‚˜ì”©ë§Œ í•´."
                        "ì‚¬ìš©ìì˜ ëŒ€ë‹µì—ëŠ” ê³µê°ë„ í‘œí˜„í•˜ê¸°ë„ í•˜ê³ , ë‹µë³€ ë‚´ìš©ì— ë§ëŠ” ì§ˆë¬¸ë„ í•´ì¤˜."
                        "ê·¸ë¦¬ê³  ë‹µë³€ì€ í•œ ë¬¸ì¥ ì´ë‚´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í•´ì¤˜. ì§ˆë¬¸ì´ë‚˜ ë‹µë³€ì´ ëŠê¸°ì§€ ì•Šì•˜ìœ¼ë©´ ì¢‹ê² ì–´."
                    )
                ),
                input_audio_transcription={},
                output_audio_transcription={}
            )

            async with client.aio.live.connect(model=MODEL, config=CONFIG) as session:
                self.session = session
                self.audio_in_queue = asyncio.Queue(maxsize=192)
                self.out_queue = asyncio.Queue(maxsize=5)

                await session.send_client_content(
                    turns={
                        "role": "user",
                        "parts": [
                            {
                                "text": "ì˜¤ëŠ˜ í•˜ë£¨ ì¼ê¸°ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ê°„ë‹¨í•œ ì§ˆë¬¸ì„ ë¨¼ì € í•´ì¤˜. ì²« ì§ˆë¬¸ì€ ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”? ê°™ì€ ì§ˆë¬¸ì´ë©´ ì¢‹ê² ì–´."
                            }
                        ],
                    },
                    turn_complete=True,
                )

                # íƒœìŠ¤í¬ ìƒì„± ë° ì‹¤í–‰
                tasks = []
                try:
                    # ê° íƒœìŠ¤í¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•˜ê³  ì‹¤í–‰
                    tasks.append(asyncio.create_task(self.send_realtime()))
                    tasks.append(asyncio.create_task(self.listen_audio()))
                    tasks.append(asyncio.create_task(self.receive_audio()))
                    tasks.append(asyncio.create_task(self.play_audio()))
                    tasks.append(asyncio.create_task(self.timeout_checker()))
                    self._tasks = tasks

                    # ë©”ì¸ ë£¨í”„
                    while self.session_active:
                        await asyncio.sleep(0.5)
                    print("ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

                finally:
                    # ì„¸ì…˜ ì¢…ë£Œ ì²˜ë¦¬
                    self.session_active = False
                    
                    # íƒœìŠ¤í¬ ì •ë¦¬ - ìƒˆë¡œìš´ ë°©ì‹
                    for task in tasks:
                        if not task.done():
                            try:
                                # íƒœìŠ¤í¬ ì·¨ì†Œ ì‹œë„
                                task.cancel()
                            except Exception:
                                pass
                    
                    # ëª¨ë“  íƒœìŠ¤í¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                    pending = [t for t in tasks if not t.done()]
                    if pending:
                        try:
                            # íƒ€ì„ì•„ì›ƒì„ 0.1ì´ˆë¡œ ì¤„ì—¬ì„œ ë¹ ë¥´ê²Œ ì¢…ë£Œ
                            await asyncio.wait(pending, timeout=0.1)
                        except asyncio.TimeoutError:
                            pass

        except asyncio.CancelledError:
            pass
        except KeyboardInterrupt:
            # Ctrl+Cë¡œ ì¢…ë£Œë  ë•Œ ëŒ€í™” ê¸°ë¡ ì €ì¥
            with open("conversation_log.json", "w", encoding="utf-8") as f:
                json.dump(self.conversation_log, f, ensure_ascii=False, indent=2)
            print("ëŒ€í™” ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except ExceptionGroup as EG:
            if hasattr(self, "audio_stream") and self.audio_stream is not None:
                self.audio_stream.close()
            # ì˜ˆì™¸ ê·¸ë£¹ì˜ ê° ì˜ˆì™¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬
            for exc in EG.exceptions:
                if isinstance(exc, websockets.exceptions.ConnectionClosedOK):
                    continue
                print(f"ì˜¤ë¥˜ ë°œìƒ: {str(exc)}")
        except websockets.exceptions.ConnectionClosedOK:
            # ì •ìƒì ì¸ ì¢…ë£Œ ë©”ì‹œì§€ëŠ” ì¶œë ¥í•˜ì§€ ì•ŠìŒ
            pass
        finally:
            # ìµœì¢… ì •ë¦¬
            if hasattr(self, '_tasks'):
                self.session_active = False
                for task in self._tasks:
                    if not task.done():
                        try:
                            # íƒœìŠ¤í¬ ì·¨ì†Œ ì‹œë„
                            task.cancel()
                        except Exception:
                            pass
                
                # ë‚¨ì€ íƒœìŠ¤í¬ ì •ë¦¬
                pending = [t for t in self._tasks if not t.done()]
                if pending:
                    try:
                        # íƒ€ì„ì•„ì›ƒì„ 0.1ì´ˆë¡œ ì¤„ì—¬ì„œ ë¹ ë¥´ê²Œ ì¢…ë£Œ
                        await asyncio.wait(pending, timeout=0.1)
                    except asyncio.TimeoutError:
                        pass
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            with open("conversation_log.json", "w", encoding="utf-8") as f:
                json.dump(self.conversation_log, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    main = AudioLoop(video_mode="none")
    asyncio.run(main.run())
