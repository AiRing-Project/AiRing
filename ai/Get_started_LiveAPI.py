# -*- coding: utf-8 -*-
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
## Run

To run the script:

```
python Get_started_LiveAPI.py
```
"""

import asyncio
import os
import sys
import traceback

import pyaudio
import json
from google import genai
from google.genai import types

from dotenv import load_dotenv

load_dotenv(".env")

try:
    api_key = os.environ["GOOGLE_API_KEY"]
except KeyError as exc:
    raise RuntimeError(
        "Environment variable GOOGLE_API_KEY is not set. "
        "Create a .env file or export the variable before running."
    ) from exc

client = genai.Client(api_key=api_key)


if sys.version_info < (3, 11, 0):
    import taskgroup, exceptiongroup

    asyncio.TaskGroup = taskgroup.TaskGroup
    asyncio.ExceptionGroup = exceptiongroup.ExceptionGroup
    ExceptionGroup = exceptiongroup.ExceptionGroup

FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 24000
CHUNK_SIZE = 2048

MODEL = "models/gemini-2.0-flash-live-001"

DEFAULT_MODE = "none"


CONFIG = types.LiveConnectConfig(
    response_modalities=["AUDIO"],
    speech_config=types.SpeechConfig(language_code="ko-KR"),
    system_instruction=types.Part(
        text=(
            "ë„ˆëŠ” ì˜¤ëŠ˜ í•˜ë£¨ ì¼ê¸° ìž‘ì„±ì„ ë•ëŠ” ëŒ€í™” ë„ìš°ë¯¸ì•¼."
            "ì‚¬ìš©ìžì—ê²Œ ì˜¤ëŠ˜ ì–´ë–¤ ì¼ì´ ìžˆì—ˆëŠ”ì§€, ê¸°ë¶„ì€ ì–´ë• ëŠ”ì§€, ê¸°ì–µì— ë‚¨ëŠ” ì¼ì€ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ìžì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ì°¨ê·¼ì°¨ê·¼ í•˜ë‚˜ì”© ì§ˆë¬¸í•´ì¤˜."
            "ì¼ê¸° ìž‘ì„±ì— ë„ì›€ì´ ë  ë§Œí•œ ì§ˆë¬¸ì„ ì´ì–´ê°€ê³ , í•œ ë²ˆì— ì§ˆë¬¸ì€ í•˜ë‚˜ì”©ë§Œ í•´."
            "ì‚¬ìš©ìžì˜ ëŒ€ë‹µì—ëŠ” ê³µê°ë„ í‘œí˜„í•˜ê¸°ë„ í•˜ê³ , ë‹µë³€ ë‚´ìš©ì— ë§žëŠ” ì§ˆë¬¸ë„ í•´ì¤˜."
            "ê·¸ë¦¬ê³  ë‹µë³€ì€ í•œ ë¬¸ìž¥ ì´ë‚´ë¡œ ìžì—°ìŠ¤ëŸ½ê²Œ í•´ì¤˜. ì§ˆë¬¸ì´ë‚˜ ë‹µë³€ì´ ëŠê¸°ì§€ ì•Šì•˜ìœ¼ë©´ ì¢‹ê² ì–´."
        )
    ),
    input_audio_transcription={},
    output_audio_transcription={},
)

pya = pyaudio.PyAudio()


class AudioLoop:
    def __init__(self, video_mode=DEFAULT_MODE):
        self.video_mode = video_mode

        self.audio_in_queue = None
        self.out_queue = None

        self.session = None

        self.receive_audio_task = None
        self.play_audio_task = None

        self.conversation_log = []
        self.ai_buffer = "" #AI ì‘ë‹µ ëˆ„ì  ë²„í¼ ì¶”ê°€
        self.user_buffer = "" #ì‚¬ìš©ìž ì‘ë‹µ ëˆ„ì  ë²„í¼ ì¶”ê°€

    async def send_realtime(self):
        while True:
            msg = await self.out_queue.get()
            blob = types.Blob(data=msg["data"], mime_type="audio/pcm;rate=16000")
            await self.session.send_realtime_input(audio=blob)

    async def listen_audio(self):
        mic_info = pya.get_default_input_device_info()
        self.audio_stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )
        if __debug__:
            kwargs = {"exception_on_overflow": False}
        else:
            kwargs = {}
        while True:
            data = await asyncio.to_thread(self.audio_stream.read, CHUNK_SIZE, **kwargs)
            await self.out_queue.put({"data": data, "mime_type": "audio/pcm"})

    async def receive_audio(self):
        "Background task to reads from the websocket and write pcm chunks to the output queue"
        while True:
            turn = self.session.receive()
            async for response in turn:

                # ì‚¬ìš©ìž ìŒì„± í…ìŠ¤íŠ¸ ëˆ„ì  (ë¶€ë¶„ ì‘ë‹µ)
                if (
                hasattr(response, "server_content")
                and hasattr(response.server_content, "input_transcription")
                and response.server_content.input_transcription
                and hasattr(response.server_content.input_transcription, "text")
                and response.server_content.input_transcription.text):
                    
                    user_text = response.server_content.input_transcription.text
                    self.user_buffer += user_text
        
                
                # AI ì‘ë‹µ í…ìŠ¤íŠ¸ ëˆ„ì  (ë¶€ë¶„ ì‘ë‹µ)
                if (
                hasattr(response, "server_content")
                and hasattr(response.server_content, "output_transcription")
                and response.server_content.output_transcription
                and hasattr(response.server_content.output_transcription, "text")
                and response.server_content.output_transcription.text):
                    
                    ai_text = response.server_content.output_transcription.text
                    self.ai_buffer += ai_text

                # í„´ ì¢…ë£Œ ì‹ í˜¸(turn_complete)ì—ì„œ í•œ ë²ˆì— ì €ìž¥
                if (
                hasattr(response, "server_content")
                and hasattr(response.server_content, "turn_complete")
                and response.server_content.turn_complete):
                    
                    if self.user_buffer.strip():
                        self.conversation_log.append({"role": "USER", "text": self.user_buffer.strip()})
                        self.user_buffer = ""
                    if self.ai_buffer.strip():
                        self.conversation_log.append({"role": "AI", "text": self.ai_buffer.strip()})
                        self.ai_buffer = ""

                if data := response.data:
                    self.audio_in_queue.put_nowait(data)
                    continue
                if text := response.text:
                    print(text, end="")

            while not self.audio_in_queue.empty():
                self.audio_in_queue.get_nowait()

    async def play_audio(self):
        stream = await asyncio.to_thread(
            pya.open,
            format=FORMAT,
            channels=CHANNELS,
            rate=RECEIVE_SAMPLE_RATE,
            output=True,
        )
        
        # ì˜¤ë””ì˜¤ ë²„í¼ ê´€ë¦¬
        buffer = []
        initial_buffer_size = 10  # ìž¬ìƒ ì‹œìž‘ ì „ ì´ˆê¸° ë²„í¼ í¬ê¸°
        minimum_buffer_size = 5   # ìž¬ìƒ ì¤‘ ìµœì†Œ ë²„í¼ í¬ê¸°
        
        print("ðŸ”Š ì˜¤ë””ì˜¤ ë²„í¼ ì¤€ë¹„ ì¤‘...")
        
        # ì´ˆê¸° ë²„í¼ ì±„ìš°ê¸°
        while len(buffer) < initial_buffer_size:
            try:
                if not self.audio_in_queue.empty():
                    chunk = await asyncio.wait_for(self.audio_in_queue.get(), timeout=0.1)
                    buffer.append(chunk)
                else:
                    await asyncio.sleep(0.05)
            except asyncio.TimeoutError:
                continue
            except asyncio.CancelledError:
                return
        
        print("ðŸ”Š ì˜¤ë””ì˜¤ ìž¬ìƒ ì‹œìž‘")
        
        try:
            while True:
                # ë²„í¼ê°€ ìµœì†Œ í¬ê¸° ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ ë” ì±„ì›€
                if len(buffer) <= minimum_buffer_size:
                    refill_count = 0
                    while len(buffer) < initial_buffer_size and refill_count < 3:
                        try:
                            if not self.audio_in_queue.empty():
                                chunk = await asyncio.wait_for(self.audio_in_queue.get(), timeout=0.1)
                                buffer.append(chunk)
                                refill_count += 1
                            else:
                                break
                        except asyncio.TimeoutError:
                            break
                
                # ë²„í¼ì—ì„œ ì²­í¬ ìž¬ìƒ
                if buffer:
                    chunk = buffer.pop(0)
                    await asyncio.to_thread(stream.write, chunk)
                else:
                    # ë²„í¼ê°€ ë¹„ì—ˆìœ¼ë©´ íì—ì„œ ì§ì ‘ ê°€ì ¸ì™€ ìž¬ìƒ
                    try:
                        if not self.audio_in_queue.empty():
                            chunk = await asyncio.wait_for(self.audio_in_queue.get(), timeout=0.1)
                            await asyncio.to_thread(stream.write, chunk)
                        else:
                            # ë²„í¼ì™€ íê°€ ëª¨ë‘ ë¹„ì—ˆìœ¼ë©´ ìž ì‹œ ëŒ€ê¸°
                            await asyncio.sleep(0.02)
                    except asyncio.TimeoutError:
                        await asyncio.sleep(0.02)
        
        except asyncio.CancelledError:
            print("ðŸ”Š ì˜¤ë””ì˜¤ ìž¬ìƒ ì¤‘ë‹¨")

    async def run(self):
        try:
            async with (
                client.aio.live.connect(model=MODEL, config=CONFIG) as session,
                asyncio.TaskGroup() as tg,
            ):
                self.session = session

                self.audio_in_queue = asyncio.Queue(maxsize=192)  # ê¸°ì¡´ 96ì—ì„œ ì¦ê°€
                self.out_queue = asyncio.Queue(maxsize=5)

                await session.send_client_content(
                    turns={
                        "role": "user",
                        "parts": [
                            {
                                "text": "ì˜¤ëŠ˜ í•˜ë£¨ ì¼ê¸°ë¥¼ ìž‘ì„±í•  ìˆ˜ ìžˆë„ë¡ ê°„ë‹¨í•œ ì§ˆë¬¸ì„ ë¨¼ì € í•´ì¤˜. ì²« ì§ˆë¬¸ì€ ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë– ì…¨ë‚˜ìš”? ê°™ì€ ì§ˆë¬¸ì´ë©´ ì¢‹ê² ì–´."
                            }
                        ],
                    },
                    turn_complete=True,
                )

                tg.create_task(self.send_realtime())
                tg.create_task(self.listen_audio())

                tg.create_task(self.receive_audio())
                tg.create_task(self.play_audio())

                await asyncio.Event().wait()  # ë¬´í•œ ëŒ€ê¸°, Ctrl+cë¡œ ì¢…ë£Œ

        except asyncio.CancelledError:
            pass
        except KeyboardInterrupt:
            # Ctrl+Cë¡œ ì¢…ë£Œë  ë•Œ ëŒ€í™” ê¸°ë¡ ì €ìž¥
            with open("conversation_log.json", "w", encoding="utf-8") as f:
                json.dump(self.conversation_log, f, ensure_ascii=False, indent=2)
            print("ëŒ€í™” ê¸°ë¡ì´ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except ExceptionGroup as EG:
            if hasattr(self, "audio_stream") and self.audio_stream is not None:
                self.audio_stream.close()
            traceback.print_exception(EG)
        finally:
            with open("conversation_log.json", "w", encoding="utf-8") as f:
                json.dump(self.conversation_log, f, ensure_ascii=False, indent=2)    



if __name__ == "__main__":

    main = AudioLoop(video_mode="none")
    asyncio.run(main.run())
